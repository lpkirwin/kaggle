{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:43:38.843974Z",
     "start_time": "2019-03-16T17:43:38.838974Z"
    }
   },
   "outputs": [],
   "source": [
    "from uuid import uuid3, NAMESPACE_DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:45:18.615706Z",
     "start_time": "2019-03-16T17:45:18.612707Z"
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:02:46.578783Z",
     "start_time": "2019-03-16T18:02:46.555796Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util import get_obj_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:16.983794Z",
     "start_time": "2019-03-08T00:38:16.218213Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:03:43.471735Z",
     "start_time": "2019-03-16T18:03:43.216883Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:17.412995Z",
     "start_time": "2019-03-08T00:38:17.207377Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util import set_context, comp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:18.636277Z",
     "start_time": "2019-03-08T00:38:17.418485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpkirwin/miniconda/envs/kaggle/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.models import run_estimator_cv, PARAMS_SKOPT, get_oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:44:32.471418Z",
     "start_time": "2019-03-16T17:44:19.969959Z"
    }
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.211458Z",
     "start_time": "2019-03-08T00:38:19.001846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in data directory:\n",
      "______\n",
      "\n",
      "titanic/\n",
      "    clean.pkl\n",
      "    raw/\n",
      "        train.csv\n",
      "        test.csv\n",
      "        gender_submission.csv\n",
      "______\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_context(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:53:10.225412Z",
     "start_time": "2019-03-16T17:53:10.219419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6e0ed3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid3(NAMESPACE_DNS, repr(LGBMClassifier())))[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:53:32.248466Z",
     "start_time": "2019-03-16T17:53:32.240475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83068d77'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md5(repr(LGBMClassifier(n_estimators=3)).encode(\"utf-8\")).hexdigest()[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:05:47.442112Z",
     "start_time": "2019-03-16T18:05:47.205249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<class 'lightgbm\", 'sklearn', \"LGBMClassifier'>\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(LGBMClassifier())).split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:05:11.593344Z",
     "start_time": "2019-03-16T18:05:11.353483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'lightgbm.sklearn.LGBMClassifier'>\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(LGBMClassifier().__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:06:10.766146Z",
     "start_time": "2019-03-16T18:06:10.470318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMClassifier_04a6eff6'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_obj_ref(LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.413086Z",
     "start_time": "2019-03-08T00:38:19.214951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(comp_path(\"clean.pkl\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.606724Z",
     "start_time": "2019-03-08T00:38:19.416577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = df[~df._test]\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.820826Z",
     "start_time": "2019-03-08T00:38:19.609720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>Hickman, Mr. Lewis</td>\n",
       "      <td>0</td>\n",
       "      <td>666</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.894531</td>\n",
       "      <td>Jonkoff, Mr. Lalio</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349204</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin Embarked       Fare                Name  Parch  PassengerId  \\\n",
       "665  32.0   NaN        S  73.500000  Hickman, Mr. Lewis      0          666   \n",
       "753  23.0   NaN        S   7.894531  Jonkoff, Mr. Lalio      0          754   \n",
       "\n",
       "     Pclass   Sex  SibSp  Survived        Ticket  _test  \n",
       "665       2  male      2       0.0  S.O.C. 14879  False  \n",
       "753       3  male      0       0.0        349204  False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.029940Z",
     "start_time": "2019-03-08T00:38:19.823321Z"
    }
   },
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "X_cols = set(tr.columns) - {target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.225630Z",
     "start_time": "2019-03-08T00:38:20.033432Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tr[X_cols]\n",
    "y = tr[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.417774Z",
     "start_time": "2019-03-08T00:38:20.228569Z"
    }
   },
   "outputs": [],
   "source": [
    "est = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.773058Z",
     "start_time": "2019-03-08T00:38:20.420712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.983668Z",
     "start_time": "2019-03-08T00:38:20.777050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': Integer(low=50, high=2000),\n",
       " 'max_depth': Integer(low=1, high=8),\n",
       " 'num_leaves': Integer(low=4, high=32),\n",
       " 'learning_rate': Real(low=0.0001, high=10, prior='log-uniform', transform='identity')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS_SKOPT[\"lgb_small_trees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:21.185296Z",
     "start_time": "2019-03-08T00:38:20.987162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesSearchCV2(BayesSearchCV):\n",
    "    \n",
    "    def __init__(self, estimator, search_spaces, optimizer_kwargs=None,\n",
    "                 n_iter=50, scoring=None, fit_params=None, n_jobs=1,\n",
    "                 n_points=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "                 pre_dispatch='2*n_jobs', random_state=None,\n",
    "                 error_score='raise', return_train_score=False):\n",
    "\n",
    "        self.search_spaces = search_spaces\n",
    "        self.n_iter = n_iter\n",
    "        self.n_points = n_points\n",
    "        self.random_state = random_state\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self._check_search_space(self.search_spaces)\n",
    "        self.fit_params = fit_params\n",
    "\n",
    "        super(BayesSearchCV, self).__init__(\n",
    "            estimator=estimator, scoring=scoring,\n",
    "            n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:39:19.324138Z",
     "start_time": "2019-03-08T00:39:19.103491Z"
    }
   },
   "outputs": [],
   "source": [
    "est = BayesSearchCV2(\n",
    "    LGBMClassifier(),\n",
    "    PARAMS_SKOPT[\"lgb_big_trees\"],\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_iter=25,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:09.812698Z",
     "start_time": "2019-03-08T00:39:19.723271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV2(cv=5, error_score='raise',\n",
       "               estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                        colsample_bytree=1.0,\n",
       "                                        importance_type='split',\n",
       "                                        learning_rate=0.1, max_depth=-1,\n",
       "                                        min_child_samples=20,\n",
       "                                        min_child_weight=0.001,\n",
       "                                        min_split_gain=0.0, n_estimators=100,\n",
       "                                        n_jobs=-1, num_leaves=31,\n",
       "                                        objective=None, random_state=None,\n",
       "                                        reg_alpha=0.0, reg_lambda=0.0,\n",
       "                                        sile...\n",
       "               fit_params=None, iid=True, n_iter=25, n_jobs=-1, n_points=1,\n",
       "               optimizer_kwargs=None, pre_dispatch='2*n_jobs',\n",
       "               random_state=None, refit=True, return_train_score=False,\n",
       "               scoring='roc_auc',\n",
       "               search_spaces={'learning_rate': Real(low=0.0001, high=10, prior='log-uniform', transform='identity'),\n",
       "                              'max_depth': Integer(low=100, high=200),\n",
       "                              'n_estimators': Integer(low=5, high=500),\n",
       "                              'num_leaves': Integer(low=50, high=500)},\n",
       "               verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:17.140060Z",
     "start_time": "2019-03-08T00:40:16.902503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\\n               importance_type='split', learning_rate=0.004056945310337203,\\n               max_depth=100, min_child_samples=20, min_child_weight=0.001,\\n               min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=500,\\n               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\\n               silent=True, subsample=1.0, subsample_for_bin=200000,\\n               subsample_freq=0)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(est.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:18.902511Z",
     "start_time": "2019-03-08T00:40:18.686412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8754841319657813"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:43:20.283843Z",
     "start_time": "2019-03-08T00:43:20.025303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703953</td>\n",
       "      <td>0.832016</td>\n",
       "      <td>0.860829</td>\n",
       "      <td>0.867246</td>\n",
       "      <td>0.904749</td>\n",
       "      <td>0.833531</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163291</td>\n",
       "      <td>0.024828</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.297724</td>\n",
       "      <td>116</td>\n",
       "      <td>129</td>\n",
       "      <td>264</td>\n",
       "      <td>{'learning_rate': 0.2977244321179457, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.825823</td>\n",
       "      <td>0.886631</td>\n",
       "      <td>0.883422</td>\n",
       "      <td>0.899757</td>\n",
       "      <td>0.864708</td>\n",
       "      <td>0.031254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377628</td>\n",
       "      <td>0.079894</td>\n",
       "      <td>0.027012</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>121</td>\n",
       "      <td>346</td>\n",
       "      <td>423</td>\n",
       "      <td>{'learning_rate': 0.002639012482648878, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741107</td>\n",
       "      <td>0.824506</td>\n",
       "      <td>0.851471</td>\n",
       "      <td>0.878476</td>\n",
       "      <td>0.917026</td>\n",
       "      <td>0.842299</td>\n",
       "      <td>0.059231</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067018</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.736015</td>\n",
       "      <td>198</td>\n",
       "      <td>35</td>\n",
       "      <td>339</td>\n",
       "      <td>{'learning_rate': 0.7360145123609051, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722793</td>\n",
       "      <td>0.820949</td>\n",
       "      <td>0.866644</td>\n",
       "      <td>0.864840</td>\n",
       "      <td>0.904074</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.062405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457857</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.157341</td>\n",
       "      <td>168</td>\n",
       "      <td>416</td>\n",
       "      <td>313</td>\n",
       "      <td>{'learning_rate': 0.1573409267736521, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.732016</td>\n",
       "      <td>0.826350</td>\n",
       "      <td>0.853275</td>\n",
       "      <td>0.864305</td>\n",
       "      <td>0.899757</td>\n",
       "      <td>0.834943</td>\n",
       "      <td>0.056719</td>\n",
       "      <td>1</td>\n",
       "      <td>0.408994</td>\n",
       "      <td>0.078167</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.192573</td>\n",
       "      <td>199</td>\n",
       "      <td>390</td>\n",
       "      <td>221</td>\n",
       "      <td>{'learning_rate': 0.19257253426871168, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.833729</td>\n",
       "      <td>0.823518</td>\n",
       "      <td>0.883422</td>\n",
       "      <td>0.876872</td>\n",
       "      <td>0.912169</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.032855</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.029647</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>188</td>\n",
       "      <td>479</td>\n",
       "      <td>344</td>\n",
       "      <td>{'learning_rate': 0.012987441506001809, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.732213</td>\n",
       "      <td>0.814888</td>\n",
       "      <td>0.844719</td>\n",
       "      <td>0.843449</td>\n",
       "      <td>0.891123</td>\n",
       "      <td>0.825088</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229351</td>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>1.070652</td>\n",
       "      <td>139</td>\n",
       "      <td>407</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 1.0706519831804433, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.851203</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.848291</td>\n",
       "      <td>0.030157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175801</td>\n",
       "      <td>0.031694</td>\n",
       "      <td>0.028024</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>197</td>\n",
       "      <td>136</td>\n",
       "      <td>212</td>\n",
       "      <td>{'learning_rate': 0.0001790838790312364, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721344</td>\n",
       "      <td>0.819763</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.865374</td>\n",
       "      <td>0.908797</td>\n",
       "      <td>0.833738</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215923</td>\n",
       "      <td>0.050164</td>\n",
       "      <td>0.036828</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.405299</td>\n",
       "      <td>117</td>\n",
       "      <td>156</td>\n",
       "      <td>419</td>\n",
       "      <td>{'learning_rate': 0.4052991151205078, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616601</td>\n",
       "      <td>0.591765</td>\n",
       "      <td>0.713102</td>\n",
       "      <td>0.660829</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.665060</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049227</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.023606</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>6.277901</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>258</td>\n",
       "      <td>{'learning_rate': 6.27790119756941, 'max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.831884</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.862901</td>\n",
       "      <td>0.865775</td>\n",
       "      <td>0.899285</td>\n",
       "      <td>0.853556</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452423</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>200</td>\n",
       "      <td>397</td>\n",
       "      <td>68</td>\n",
       "      <td>{'learning_rate': 0.0006945420920857493, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.812187</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.849465</td>\n",
       "      <td>0.896452</td>\n",
       "      <td>0.847582</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041938</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0060183902294381735, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.831950</td>\n",
       "      <td>0.812714</td>\n",
       "      <td>0.860495</td>\n",
       "      <td>0.849799</td>\n",
       "      <td>0.896317</td>\n",
       "      <td>0.850141</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051006</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.026867</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.031112</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.03111221881543544, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.812648</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.851203</td>\n",
       "      <td>0.901309</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732490</td>\n",
       "      <td>0.134628</td>\n",
       "      <td>0.031783</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 100, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.833267</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>0.884759</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.899622</td>\n",
       "      <td>0.864900</td>\n",
       "      <td>0.029772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.131985</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>278</td>\n",
       "      <td>{'learning_rate': 0.0017203748216870895, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.844137</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.899398</td>\n",
       "      <td>0.886230</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>0.875484</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>1</td>\n",
       "      <td>1.308815</td>\n",
       "      <td>0.269615</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.004056945310337203, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.758235</td>\n",
       "      <td>0.821212</td>\n",
       "      <td>0.864505</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.913384</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>1</td>\n",
       "      <td>1.041618</td>\n",
       "      <td>0.185715</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>0.024162</td>\n",
       "      <td>0.032062</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.03206190594505763, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.831225</td>\n",
       "      <td>0.807378</td>\n",
       "      <td>0.862366</td>\n",
       "      <td>0.862166</td>\n",
       "      <td>0.898610</td>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932217</td>\n",
       "      <td>0.177784</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0004947753799249815, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.844269</td>\n",
       "      <td>0.830040</td>\n",
       "      <td>0.896056</td>\n",
       "      <td>0.880080</td>\n",
       "      <td>0.915812</td>\n",
       "      <td>0.873123</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.216482</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.005864857043917789, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.858088</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.848184</td>\n",
       "      <td>0.030141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072527</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.027739</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>121</td>\n",
       "      <td>21</td>\n",
       "      <td>473</td>\n",
       "      <td>{'learning_rate': 0.0011029916619564796, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.843874</td>\n",
       "      <td>0.827866</td>\n",
       "      <td>0.889037</td>\n",
       "      <td>0.878008</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>0.870710</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809535</td>\n",
       "      <td>0.155446</td>\n",
       "      <td>0.037593</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.008461002863885693, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.843874</td>\n",
       "      <td>0.837022</td>\n",
       "      <td>0.899666</td>\n",
       "      <td>0.885963</td>\n",
       "      <td>0.910483</td>\n",
       "      <td>0.875284</td>\n",
       "      <td>0.029664</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807107</td>\n",
       "      <td>0.163667</td>\n",
       "      <td>0.038133</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0040389814497028735, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.811265</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.854412</td>\n",
       "      <td>0.893551</td>\n",
       "      <td>0.847809</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063431</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>0.026893</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 122, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.844005</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.899398</td>\n",
       "      <td>0.885561</td>\n",
       "      <td>0.910483</td>\n",
       "      <td>0.875163</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850174</td>\n",
       "      <td>0.175890</td>\n",
       "      <td>0.036658</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.004105298666035359, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.840184</td>\n",
       "      <td>0.832938</td>\n",
       "      <td>0.897995</td>\n",
       "      <td>0.888302</td>\n",
       "      <td>0.910618</td>\n",
       "      <td>0.873882</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754180</td>\n",
       "      <td>0.151409</td>\n",
       "      <td>0.040473</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>111</td>\n",
       "      <td>493</td>\n",
       "      <td>63</td>\n",
       "      <td>{'learning_rate': 0.0032152317894181414, 'max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.703953           0.832016           0.860829   \n",
       "1            0.828524           0.825823           0.886631   \n",
       "2            0.741107           0.824506           0.851471   \n",
       "3            0.722793           0.820949           0.866644   \n",
       "4            0.732016           0.826350           0.853275   \n",
       "5            0.833729           0.823518           0.883422   \n",
       "6            0.732213           0.814888           0.844719   \n",
       "7            0.822200           0.812385           0.858222   \n",
       "8            0.721344           0.819763           0.854545   \n",
       "9            0.616601           0.591765           0.713102   \n",
       "10           0.831884           0.808564           0.862901   \n",
       "11           0.822200           0.812187           0.858222   \n",
       "12           0.831950           0.812714           0.860495   \n",
       "13           0.822266           0.812648           0.858222   \n",
       "14           0.833267           0.825626           0.884759   \n",
       "15           0.844137           0.836957           0.899398   \n",
       "16           0.758235           0.821212           0.864505   \n",
       "17           0.831225           0.807378           0.862366   \n",
       "18           0.844269           0.830040           0.896056   \n",
       "19           0.822200           0.812385           0.858088   \n",
       "20           0.843874           0.827866           0.889037   \n",
       "21           0.843874           0.837022           0.899666   \n",
       "22           0.822200           0.811265           0.858222   \n",
       "23           0.844005           0.836957           0.899398   \n",
       "24           0.840184           0.832938           0.897995   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.867246           0.904749         0.833531        0.068972   \n",
       "1            0.883422           0.899757         0.864708        0.031254   \n",
       "2            0.878476           0.917026         0.842299        0.059231   \n",
       "3            0.864840           0.904074         0.835640        0.062405   \n",
       "4            0.864305           0.899757         0.834943        0.056719   \n",
       "5            0.876872           0.912169         0.865806        0.032855   \n",
       "6            0.843449           0.891123         0.825088        0.052577   \n",
       "7            0.851203           0.898071         0.848291        0.030157   \n",
       "8            0.865374           0.908797         0.833738        0.063108   \n",
       "9            0.660829           0.744131         0.665060        0.057076   \n",
       "10           0.865775           0.899285         0.853556        0.031044   \n",
       "11           0.849465           0.896452         0.847582        0.029646   \n",
       "12           0.849799           0.896317         0.850141        0.028158   \n",
       "13           0.851203           0.901309         0.849000        0.031154   \n",
       "14           0.881818           0.899622         0.864900        0.029772   \n",
       "15           0.886230           0.911292         0.875484        0.029794   \n",
       "16           0.863770           0.913384         0.844021        0.051966   \n",
       "17           0.862166           0.898610         0.852223        0.030990   \n",
       "18           0.880080           0.915812         0.873123        0.031889   \n",
       "19           0.850802           0.898071         0.848184        0.030141   \n",
       "20           0.878008           0.915407         0.870710        0.031434   \n",
       "21           0.885963           0.910483         0.875284        0.029664   \n",
       "22           0.854412           0.893551         0.847809        0.029087   \n",
       "23           0.885561           0.910483         0.875163        0.029581   \n",
       "24           0.888302           0.910618         0.873882        0.031475   \n",
       "\n",
       "    rank_test_score  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "0                 1       0.163291      0.024828         0.025346   \n",
       "1                 1       0.377628      0.079894         0.027012   \n",
       "2                 1       0.067018      0.009533         0.020696   \n",
       "3                 1       0.457857      0.066750         0.032746   \n",
       "4                 1       0.408994      0.078167         0.032638   \n",
       "5                 1       0.599798      0.115798         0.029647   \n",
       "6                 1       0.229351      0.045483         0.027801   \n",
       "7                 1       0.175801      0.031694         0.028024   \n",
       "8                 1       0.215923      0.050164         0.036828   \n",
       "9                 1       0.049227      0.012001         0.023606   \n",
       "10                1       0.452423      0.090967         0.026894   \n",
       "11                1       0.041938      0.004884         0.022457   \n",
       "12                1       0.051006      0.009252         0.026867   \n",
       "13                1       0.732490      0.134628         0.031783   \n",
       "14                1       0.682620      0.131985         0.032513   \n",
       "15                1       1.308815      0.269615         0.057884   \n",
       "16                1       1.041618      0.185715         0.071604   \n",
       "17                1       0.932217      0.177784         0.042997   \n",
       "18                1       0.949936      0.216482         0.045258   \n",
       "19                1       0.072527      0.008840         0.027739   \n",
       "20                1       0.809535      0.155446         0.037593   \n",
       "21                1       0.807107      0.163667         0.038133   \n",
       "22                1       0.063431      0.019384         0.026893   \n",
       "23                1       0.850174      0.175890         0.036658   \n",
       "24                1       0.754180      0.151409         0.040473   \n",
       "\n",
       "    std_score_time  param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "0         0.005761             0.297724              116                 129   \n",
       "1         0.005481             0.002639              121                 346   \n",
       "2         0.003708             0.736015              198                  35   \n",
       "3         0.006395             0.157341              168                 416   \n",
       "4         0.006316             0.192573              199                 390   \n",
       "5         0.005853             0.012987              188                 479   \n",
       "6         0.006957             1.070652              139                 407   \n",
       "7         0.006561             0.000179              197                 136   \n",
       "8         0.016467             0.405299              117                 156   \n",
       "9         0.006100             6.277901              120                  47   \n",
       "10        0.005487             0.000695              200                 397   \n",
       "11        0.004292             0.006018              200                   5   \n",
       "12        0.005298             0.031112              200                   5   \n",
       "13        0.003293             0.000100              100                 500   \n",
       "14        0.006348             0.001720              200                 500   \n",
       "15        0.014355             0.004057              100                 500   \n",
       "16        0.024162             0.032062              100                 500   \n",
       "17        0.008691             0.000495              100                 500   \n",
       "18        0.009621             0.005865              200                 500   \n",
       "19        0.003678             0.001103              121                  21   \n",
       "20        0.006973             0.008461              100                 500   \n",
       "21        0.007796             0.004039              200                 500   \n",
       "22        0.004295             0.000100              122                   5   \n",
       "23        0.009162             0.004105              200                 500   \n",
       "24        0.008938             0.003215              111                 493   \n",
       "\n",
       "    param_num_leaves                                             params  \n",
       "0                264  {'learning_rate': 0.2977244321179457, 'max_dep...  \n",
       "1                423  {'learning_rate': 0.002639012482648878, 'max_d...  \n",
       "2                339  {'learning_rate': 0.7360145123609051, 'max_dep...  \n",
       "3                313  {'learning_rate': 0.1573409267736521, 'max_dep...  \n",
       "4                221  {'learning_rate': 0.19257253426871168, 'max_de...  \n",
       "5                344  {'learning_rate': 0.012987441506001809, 'max_d...  \n",
       "6                250  {'learning_rate': 1.0706519831804433, 'max_dep...  \n",
       "7                212  {'learning_rate': 0.0001790838790312364, 'max_...  \n",
       "8                419  {'learning_rate': 0.4052991151205078, 'max_dep...  \n",
       "9                258  {'learning_rate': 6.27790119756941, 'max_depth...  \n",
       "10                68  {'learning_rate': 0.0006945420920857493, 'max_...  \n",
       "11                50  {'learning_rate': 0.0060183902294381735, 'max_...  \n",
       "12               500  {'learning_rate': 0.03111221881543544, 'max_de...  \n",
       "13               500  {'learning_rate': 0.0001, 'max_depth': 100, 'n...  \n",
       "14               278  {'learning_rate': 0.0017203748216870895, 'max_...  \n",
       "15               500  {'learning_rate': 0.004056945310337203, 'max_d...  \n",
       "16                50  {'learning_rate': 0.03206190594505763, 'max_de...  \n",
       "17               500  {'learning_rate': 0.0004947753799249815, 'max_...  \n",
       "18               500  {'learning_rate': 0.005864857043917789, 'max_d...  \n",
       "19               473  {'learning_rate': 0.0011029916619564796, 'max_...  \n",
       "20               500  {'learning_rate': 0.008461002863885693, 'max_d...  \n",
       "21               500  {'learning_rate': 0.0040389814497028735, 'max_...  \n",
       "22                50  {'learning_rate': 0.0001, 'max_depth': 122, 'n...  \n",
       "23               500  {'learning_rate': 0.004105298666035359, 'max_d...  \n",
       "24                63  {'learning_rate': 0.0032152317894181414, 'max_...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(est.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:43:50.467903Z",
     "start_time": "2019-03-08T00:43:49.436824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10208162, 0.84251394, 0.34053742, 0.84251394, 0.17294969,\n",
       "       0.13715396, 0.10391543, 0.36130271, 0.36396468, 0.83091414,\n",
       "       0.62831723, 0.67176353, 0.22430298, 0.08425937, 0.56168607,\n",
       "       0.67176353, 0.26373112, 0.13224226, 0.51568949, 0.59879854,\n",
       "       0.05815338, 0.08043304, 0.50800132, 0.22887952, 0.42450412,\n",
       "       0.11005445, 0.04785602, 0.19128479, 0.59360634, 0.04827733,\n",
       "       0.24285582, 0.78023817, 0.59879854, 0.1421908 , 0.25596264,\n",
       "       0.23587212, 0.04785829, 0.19579534, 0.53790005, 0.51313868,\n",
       "       0.33281318, 0.7354459 , 0.05074379, 0.83091414, 0.49587347,\n",
       "       0.190341  , 0.13135231, 0.59879854, 0.1273358 , 0.53790005,\n",
       "       0.26373112, 0.10363613, 0.84251394, 0.7354459 , 0.10391543,\n",
       "       0.10884462, 0.7354459 , 0.13926464, 0.7354459 , 0.08227747,\n",
       "       0.11268771, 0.84251394, 0.14740429, 0.26373112, 0.10884462,\n",
       "       0.13736069, 0.7354459 , 0.22430298, 0.42166984, 0.11560954,\n",
       "       0.12946108, 0.11686448, 0.11597001, 0.13674021, 0.13402456,\n",
       "       0.13941864, 0.04827733, 0.190341  , 0.42597543, 0.36486704,\n",
       "       0.10379114, 0.11391321, 0.59879854, 0.22887952, 0.7354459 ,\n",
       "       0.51568949, 0.15664273, 0.190341  , 0.76361575, 0.19579534,\n",
       "       0.18328827, 0.10363613, 0.14740429, 0.11263029, 0.04408372,\n",
       "       0.190341  , 0.10391543, 0.25596264, 0.7354459 , 0.05800241,\n",
       "       0.39105507, 0.04827733, 0.25596264, 0.08043304, 0.14369462,\n",
       "       0.13441812, 0.44060588, 0.04838276, 0.04732849, 0.13245974,\n",
       "       0.14740429, 0.52894781, 0.19579534, 0.34384923, 0.52643989,\n",
       "       0.19579534, 0.04754886, 0.10271663, 0.25596264, 0.11686448,\n",
       "       0.08264996, 0.190341  , 0.14188845, 0.7354459 , 0.10391543,\n",
       "       0.20168934, 0.04921182, 0.10538239, 0.48183841, 0.04365576,\n",
       "       0.05130793, 0.10538239, 0.36486704, 0.7354459 , 0.10368129,\n",
       "       0.11543541, 0.7354459 , 0.26349992, 0.18776199, 0.25596264,\n",
       "       0.5170661 , 0.44060588, 0.52854995, 0.10928801, 0.12079164,\n",
       "       0.1153548 , 0.13479654, 0.11686448, 0.05852217, 0.09752601,\n",
       "       0.09705748, 0.83091414, 0.20365672, 0.07342366, 0.04553539,\n",
       "       0.14740429, 0.61163848, 0.18939915, 0.13224226, 0.10317115,\n",
       "       0.07342366, 0.67176353, 0.13693767, 0.12091717, 0.26373112,\n",
       "       0.28058607, 0.84251394, 0.11005445, 0.17221771, 0.28704702,\n",
       "       0.17162929, 0.27832859, 0.43215248, 0.09765323, 0.17162929,\n",
       "       0.14531935, 0.08322498, 0.90896229, 0.19483575, 0.11614678,\n",
       "       0.16333102, 0.2977042 , 0.29909032, 0.26373112, 0.45543038,\n",
       "       0.19810334, 0.67240199, 0.15229067, 0.13450207, 0.11518366,\n",
       "       0.7354459 , 0.0936478 , 0.41904535, 0.46645757, 0.67176353,\n",
       "       0.78023817, 0.16642099, 0.26575641, 0.59879854, 0.89431018,\n",
       "       0.26313577, 0.1023111 , 0.12396892, 0.16950128, 0.06204956,\n",
       "       0.65477998, 0.1819931 , 0.17428929, 0.73008579, 0.33304886,\n",
       "       0.16260506, 0.88266275, 0.14226157, 0.20489597, 0.14349973,\n",
       "       0.9010526 , 0.64234533, 0.16190614, 0.90912605, 0.26297834,\n",
       "       0.12752639, 0.2050283 , 0.18336524, 0.10575713, 0.28692437,\n",
       "       0.088008  , 0.06843213, 0.14748931, 0.0936478 , 0.16333102,\n",
       "       0.88426264, 0.27770592, 0.14079537, 0.13130664, 0.09731885,\n",
       "       0.82589467, 0.09194496, 0.90908649, 0.06843213, 0.20950622,\n",
       "       0.64959039, 0.69995769, 0.26297834, 0.14602893, 0.21037216,\n",
       "       0.18546963, 0.69853188, 0.89431018, 0.30739302, 0.08485277,\n",
       "       0.11088174, 0.55035602, 0.20617559, 0.10651724, 0.40072024,\n",
       "       0.4275765 , 0.9212625 , 0.90201704, 0.9010526 , 0.88266275,\n",
       "       0.16642099, 0.29909032, 0.24342989, 0.19579032, 0.82589467,\n",
       "       0.22730102, 0.08353318, 0.16556912, 0.89336922, 0.89336119,\n",
       "       0.31913553, 0.16260506, 0.88512854, 0.36322209, 0.82589467,\n",
       "       0.88409053, 0.68456018, 0.10444575, 0.29909032, 0.3946816 ,\n",
       "       0.15177508, 0.21766916, 0.13964136, 0.06204956, 0.18668877,\n",
       "       0.24982341, 0.26297834, 0.11192369, 0.18350637, 0.73954375,\n",
       "       0.87529059, 0.90150443, 0.24174864, 0.63842405, 0.12398156,\n",
       "       0.33968748, 0.23801169, 0.89159049, 0.33872186, 0.90106012,\n",
       "       0.82589467, 0.06632947, 0.1107505 , 0.917242  , 0.14649807,\n",
       "       0.68518843, 0.91433055, 0.89159049, 0.17662873, 0.90912285,\n",
       "       0.90060541, 0.89159049, 0.8149038 , 0.21766916, 0.1101562 ,\n",
       "       0.65705042, 0.88184628, 0.14079537, 0.89336119, 0.90119766,\n",
       "       0.14226157, 0.21766916, 0.8972496 , 0.89123775, 0.1023111 ,\n",
       "       0.9010526 , 0.11614678, 0.88512854, 0.39133034, 0.90908649,\n",
       "       0.42560359, 0.35403091, 0.27541937, 0.06316664, 0.91433055,\n",
       "       0.10575713, 0.46427257, 0.90106012, 0.19691957, 0.33339197,\n",
       "       0.73274177, 0.88168967, 0.2050283 , 0.09224096, 0.19192083,\n",
       "       0.89431018, 0.88512854, 0.68949852, 0.7315553 , 0.19592724,\n",
       "       0.0899206 , 0.32959014, 0.25509458, 0.06875435, 0.1833693 ,\n",
       "       0.26313577, 0.90060541, 0.88512854, 0.75008186, 0.75008186,\n",
       "       0.21000011, 0.34327948, 0.41252295, 0.11969119, 0.23465958,\n",
       "       0.32833962, 0.91963625, 0.57977149, 0.75008186, 0.91963613,\n",
       "       0.36180914, 0.14367923, 0.20166817, 0.30347036, 0.58336012,\n",
       "       0.90714429, 0.63546872, 0.31560303, 0.27181857, 0.14839787,\n",
       "       0.9047375 , 0.66950185, 0.43663958, 0.91963625, 0.09505718,\n",
       "       0.19200765, 0.30256022, 0.75297695, 0.1338957 , 0.81835204,\n",
       "       0.29659353, 0.1532288 , 0.252835  , 0.92172981, 0.52234266,\n",
       "       0.14941017, 0.57186966, 0.19689869, 0.10254969, 0.82810048,\n",
       "       0.21419438, 0.2096914 , 0.54050058, 0.16365066, 0.56711164,\n",
       "       0.17914056, 0.18143677, 0.74229145, 0.1532288 , 0.1749311 ,\n",
       "       0.09505718, 0.0966134 , 0.91963613, 0.0966134 , 0.23421594,\n",
       "       0.41862296, 0.91963607, 0.81835204, 0.3859147 , 0.45217389,\n",
       "       0.20991512, 0.15301446, 0.17336226, 0.43477617, 0.15791033,\n",
       "       0.1338957 , 0.82810048, 0.81835204, 0.14176541, 0.43663958,\n",
       "       0.41810046, 0.53559862, 0.75297695, 0.14927149, 0.22301931,\n",
       "       0.9006842 , 0.19465164, 0.81835204, 0.15783654, 0.39390412,\n",
       "       0.75297695, 0.16017792, 0.20977024, 0.82810048, 0.1751649 ,\n",
       "       0.70989497, 0.81835204, 0.41810046, 0.66950185, 0.24268924,\n",
       "       0.25277141, 0.22729174, 0.41810046, 0.17170347, 0.1751649 ,\n",
       "       0.25143682, 0.24027824, 0.90714429, 0.75297695, 0.14176541,\n",
       "       0.26266479, 0.24966439, 0.15687832, 0.28248541, 0.1751649 ,\n",
       "       0.11969119, 0.0966134 , 0.24268924, 0.1338957 , 0.66950185,\n",
       "       0.1338957 , 0.19728355, 0.82810048, 0.81835204, 0.54050058,\n",
       "       0.25843144, 0.17914056, 0.16872152, 0.15626484, 0.54282567,\n",
       "       0.16229036, 0.0966134 , 0.23655434, 0.40414341, 0.2904982 ,\n",
       "       0.1749311 , 0.91963625, 0.24027824, 0.42839603, 0.55955124,\n",
       "       0.22729174, 0.16022567, 0.24268924, 0.13703659, 0.14678739,\n",
       "       0.34968754, 0.91963625, 0.1730093 , 0.9047375 , 0.17650052,\n",
       "       0.18947855, 0.72047514, 0.75008186, 0.4913309 , 0.90068072,\n",
       "       0.27901581, 0.82810048, 0.335372  , 0.18768507, 0.24219473,\n",
       "       0.22856174, 0.1751649 , 0.41810046, 0.91963625, 0.18432871,\n",
       "       0.16299416, 0.75297695, 0.21959955, 0.75297695, 0.25706229,\n",
       "       0.91963613, 0.10561167, 0.20508761, 0.91963625, 0.27164238,\n",
       "       0.17003907, 0.75297695, 0.24244319, 0.21419438, 0.10257628,\n",
       "       0.81835204, 0.27164238, 0.28291398, 0.65892736, 0.52687909,\n",
       "       0.89302868, 0.31549158, 0.9220094 , 0.1730093 , 0.89202229,\n",
       "       0.91967487, 0.23474664, 0.23474664, 0.05268223, 0.38445042,\n",
       "       0.07430615, 0.87543401, 0.11391139, 0.0900477 , 0.60160916,\n",
       "       0.38277152, 0.05991357, 0.0977351 , 0.16826679, 0.36762352,\n",
       "       0.16189637, 0.86669267, 0.2898312 , 0.92032063, 0.39002575,\n",
       "       0.13808062, 0.07928568, 0.06229079, 0.12086659, 0.37994808,\n",
       "       0.09089976, 0.07502085, 0.25888571, 0.12675421, 0.11802293,\n",
       "       0.05150435, 0.86669267, 0.57068463, 0.66839882, 0.12992449,\n",
       "       0.08519312, 0.89789279, 0.86669267, 0.53934965, 0.20768423,\n",
       "       0.87636009, 0.9209288 , 0.04844379, 0.46987175, 0.19510928,\n",
       "       0.90495179, 0.05242343, 0.11901402, 0.11036425, 0.12086659,\n",
       "       0.07474769, 0.92032063, 0.07283655, 0.66839882, 0.05268223,\n",
       "       0.09343001, 0.91989916, 0.07283655, 0.12675421, 0.38580676,\n",
       "       0.8594365 , 0.062992  , 0.29304468, 0.16478392, 0.57068463,\n",
       "       0.0900477 , 0.14063951, 0.55027284, 0.88209332, 0.88195234,\n",
       "       0.14646   , 0.05019961, 0.65892736, 0.13808062, 0.16182743,\n",
       "       0.87636009, 0.09727197, 0.46265236, 0.89758568, 0.06596881,\n",
       "       0.26171914, 0.48738923, 0.173587  , 0.07492735, 0.08270605,\n",
       "       0.12752273, 0.06528241, 0.90495179, 0.12629605, 0.09378699,\n",
       "       0.16189637, 0.07283655, 0.5631096 , 0.0958071 , 0.23474664,\n",
       "       0.90261745, 0.20768423, 0.05991357, 0.14646   , 0.08770933,\n",
       "       0.07766947, 0.88670986, 0.25092902, 0.2404702 , 0.68646202,\n",
       "       0.38445042, 0.07744474, 0.12752273, 0.0614027 , 0.3705251 ,\n",
       "       0.06505458, 0.89302868, 0.09317173, 0.66891495, 0.65351577,\n",
       "       0.23931553, 0.06505458, 0.44202209, 0.06178523, 0.11901402,\n",
       "       0.38445042, 0.13631879, 0.12246425, 0.08329436, 0.11694907,\n",
       "       0.2878638 , 0.06852721, 0.09710093, 0.16478392, 0.91989916,\n",
       "       0.86669267, 0.45357191, 0.05150435, 0.06926964, 0.05082264,\n",
       "       0.12808649, 0.13528575, 0.47374277, 0.14646   , 0.49386591,\n",
       "       0.54637688, 0.4993837 , 0.09617931, 0.08268585, 0.08314469,\n",
       "       0.22169837, 0.08268585, 0.09895184, 0.13080709, 0.85641234,\n",
       "       0.50081562, 0.62215304, 0.2404702 , 0.2462686 , 0.16189637,\n",
       "       0.05644551, 0.16478392, 0.66839882, 0.36598992, 0.08450696,\n",
       "       0.84378234, 0.57068463, 0.57462743, 0.24029078, 0.12311846,\n",
       "       0.05268223, 0.75822395, 0.62061865, 0.89058443, 0.14688232,\n",
       "       0.90671377, 0.44644682, 0.43352672, 0.16990934, 0.06230999,\n",
       "       0.1028345 , 0.90117356, 0.90677367, 0.13370057, 0.10877388,\n",
       "       0.9159121 , 0.10266136, 0.10427524, 0.10311838, 0.73538728,\n",
       "       0.12340945, 0.91719864, 0.59842835, 0.14422753, 0.45294083,\n",
       "       0.90737734, 0.51462581, 0.05039106, 0.09778288, 0.09778288,\n",
       "       0.12155257, 0.15160254, 0.69917946, 0.05761841, 0.05761841,\n",
       "       0.35764775, 0.6983797 , 0.90119987, 0.11323378, 0.19548854,\n",
       "       0.48492393, 0.2479404 , 0.91719864, 0.72543689, 0.13134367,\n",
       "       0.91596664, 0.55351074, 0.10382356, 0.09902781, 0.91546615,\n",
       "       0.55351074, 0.13144244, 0.12288208, 0.10288316, 0.90737734,\n",
       "       0.07617011, 0.05506539, 0.1345814 , 0.90737734, 0.17676852,\n",
       "       0.90116937, 0.31185032, 0.37086899, 0.11829195, 0.11930934,\n",
       "       0.09750942, 0.07526998, 0.91014702, 0.07207267, 0.91014702,\n",
       "       0.10895609, 0.05314466, 0.50756219, 0.05027674, 0.90117356,\n",
       "       0.48501637, 0.9159121 , 0.62838546, 0.09270979, 0.12483736,\n",
       "       0.12483736, 0.47679165, 0.27651218, 0.61837902, 0.55233981,\n",
       "       0.05314466, 0.29045666, 0.2741383 , 0.35139888, 0.10142238,\n",
       "       0.10311838, 0.91014702, 0.25680693, 0.14362862, 0.15647623,\n",
       "       0.10427524, 0.91719864, 0.72048222, 0.52538445, 0.13869692,\n",
       "       0.18462589, 0.22310136, 0.47679165, 0.10311838, 0.92085153,\n",
       "       0.11222708, 0.08343266, 0.10372752, 0.2786173 , 0.16536006,\n",
       "       0.10359836, 0.48439465, 0.29938083, 0.05506539, 0.15892165,\n",
       "       0.90117356, 0.10678006, 0.22310136, 0.29588334, 0.25626029,\n",
       "       0.05039106, 0.46625886, 0.61224608, 0.05314466, 0.90117356,\n",
       "       0.26381588, 0.61837902, 0.07207267, 0.11539273, 0.12340945,\n",
       "       0.90117356, 0.11019039, 0.08335977, 0.49172915, 0.35764775,\n",
       "       0.14323551, 0.21411514, 0.91714483, 0.06591751, 0.20810462,\n",
       "       0.05493526, 0.15369825, 0.09062609, 0.21747255, 0.90737734,\n",
       "       0.27135888, 0.07526998, 0.27782396, 0.9159121 , 0.91014702,\n",
       "       0.26941907, 0.90117356, 0.46489963, 0.43157515, 0.07207267,\n",
       "       0.05963115, 0.10971291, 0.91014702, 0.2741383 , 0.09778288,\n",
       "       0.91014702, 0.90677367, 0.57712553, 0.08783454, 0.55351074,\n",
       "       0.11023342, 0.91546615, 0.22680487, 0.09046697, 0.91761038,\n",
       "       0.48501637, 0.12254797, 0.09981485, 0.05761841, 0.90117356,\n",
       "       0.90677367, 0.06413803, 0.30267908, 0.09798041, 0.12483736,\n",
       "       0.21474707, 0.09798041, 0.9159121 , 0.56565264, 0.62973073,\n",
       "       0.090365  ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_predict(est.best_estimator_, X, y, cv=5, method=\"predict_proba\")[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
