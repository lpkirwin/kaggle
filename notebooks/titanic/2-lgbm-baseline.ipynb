{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:43:38.843974Z",
     "start_time": "2019-03-16T17:43:38.838974Z"
    }
   },
   "outputs": [],
   "source": [
    "from uuid import uuid3, NAMESPACE_DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:53:10.225412Z",
     "start_time": "2019-03-16T17:53:10.219419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a6e579'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid3(NAMESPACE_DNS, repr(LGBMClassifier())))[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:45:18.615706Z",
     "start_time": "2019-03-16T17:45:18.612707Z"
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:53:32.248466Z",
     "start_time": "2019-03-16T17:53:32.240475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c950be60'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md5(repr(LGBMClassifier(n_estimators=3)).encode(\"utf-8\")).hexdigest()[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:05:47.442112Z",
     "start_time": "2019-03-16T18:05:47.205249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<class 'lightgbm\", 'sklearn', \"LGBMClassifier'>\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(LGBMClassifier())).split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:05:11.593344Z",
     "start_time": "2019-03-16T18:05:11.353483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'lightgbm.sklearn.LGBMClassifier'>\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(LGBMClassifier().__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:02:46.578783Z",
     "start_time": "2019-03-16T18:02:46.555796Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util import get_obj_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:06:10.766146Z",
     "start_time": "2019-03-16T18:06:10.470318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMClassifier_ad4f6715'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_obj_ref(LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:16.983794Z",
     "start_time": "2019-03-08T00:38:16.218213Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T18:03:43.471735Z",
     "start_time": "2019-03-16T18:03:43.216883Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:17.412995Z",
     "start_time": "2019-03-08T00:38:17.207377Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util import set_context, comp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:18.636277Z",
     "start_time": "2019-03-08T00:38:17.418485Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models import run_estimator_cv, PARAMS_SKOPT, get_oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:44:32.471418Z",
     "start_time": "2019-03-16T17:44:19.969959Z"
    }
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.211458Z",
     "start_time": "2019-03-08T00:38:19.001846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in data directory:\n",
      "______\n",
      "\n",
      "titanic/\n",
      "    clean.pkl\n",
      "    raw/\n",
      "        gender_submission.csv\n",
      "        test.csv\n",
      "        train.csv\n",
      "______\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_context(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.413086Z",
     "start_time": "2019-03-08T00:38:19.214951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(comp_path(\"clean.pkl\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.606724Z",
     "start_time": "2019-03-08T00:38:19.416577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = df[~df._test]\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:19.820826Z",
     "start_time": "2019-03-08T00:38:19.609720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>6.75</td>\n",
       "      <td>Hegarty, Miss. Hanora \"Nora\"</td>\n",
       "      <td>0</td>\n",
       "      <td>655</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365226</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>56.50</td>\n",
       "      <td>Lam, Mr. Ali</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1601</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin Embarked   Fare                          Name  Parch  \\\n",
       "654  18.0   NaN        Q   6.75  Hegarty, Miss. Hanora \"Nora\"      0   \n",
       "692   NaN   NaN        S  56.50                  Lam, Mr. Ali      0   \n",
       "\n",
       "     PassengerId  Pclass     Sex  SibSp  Survived  Ticket  _test  \n",
       "654          655       3  female      0       0.0  365226  False  \n",
       "692          693       3    male      0       1.0    1601  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.029940Z",
     "start_time": "2019-03-08T00:38:19.823321Z"
    }
   },
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "X_cols = set(tr.columns) - {target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.225630Z",
     "start_time": "2019-03-08T00:38:20.033432Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tr[X_cols]\n",
    "y = tr[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.417774Z",
     "start_time": "2019-03-08T00:38:20.228569Z"
    }
   },
   "outputs": [],
   "source": [
    "est = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.773058Z",
     "start_time": "2019-03-08T00:38:20.420712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:20.983668Z",
     "start_time": "2019-03-08T00:38:20.777050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': Integer(low=50, high=2000),\n",
       " 'max_depth': Integer(low=1, high=8),\n",
       " 'num_leaves': Integer(low=4, high=32),\n",
       " 'learning_rate': Real(low=0.0001, high=10, prior='log-uniform', transform='identity')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS_SKOPT[\"lgb_small_trees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:38:21.185296Z",
     "start_time": "2019-03-08T00:38:20.987162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:39:19.324138Z",
     "start_time": "2019-03-08T00:39:19.103491Z"
    }
   },
   "outputs": [],
   "source": [
    "est = BayesSearchCV(\n",
    "    LGBMClassifier(),\n",
    "    PARAMS_SKOPT[\"lgb_big_trees\"],\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_iter=25,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:09.812698Z",
     "start_time": "2019-03-08T00:39:19.723271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_iter=25, n_jobs=-1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "       refit=True, return_train_score=False, scoring='roc_auc',\n",
       "       search_spaces={'n_estimators': Integer(low=5, high=500), 'max_depth': Integer(low=100, high=200), 'num_leaves': Integer(low=50, high=500), 'learning_rate': Real(low=0.0001, high=10, prior='log-uniform', transform='identity')},\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:17.140060Z",
     "start_time": "2019-03-08T00:40:16.902503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\\n        importance_type='split', learning_rate=0.02135085801759193,\\n        max_depth=185, min_child_samples=20, min_child_weight=0.001,\\n        min_split_gain=0.0, n_estimators=111, n_jobs=-1, num_leaves=270,\\n        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\\n        silent=True, subsample=1.0, subsample_for_bin=200000,\\n        subsample_freq=0)\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(est.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:40:18.902511Z",
     "start_time": "2019-03-08T00:40:18.686412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751528408995995"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:43:20.283843Z",
     "start_time": "2019-03-08T00:43:20.025303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.737352</td>\n",
       "      <td>0.833992</td>\n",
       "      <td>0.847259</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.890853</td>\n",
       "      <td>0.831134</td>\n",
       "      <td>0.050790</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273891</td>\n",
       "      <td>0.051536</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.857423</td>\n",
       "      <td>150</td>\n",
       "      <td>363</td>\n",
       "      <td>247</td>\n",
       "      <td>{'learning_rate': 0.8574231231790369, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.811265</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.851604</td>\n",
       "      <td>0.893551</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121674</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.028192</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>192</td>\n",
       "      <td>55</td>\n",
       "      <td>365</td>\n",
       "      <td>{'learning_rate': 0.00011414761496439964, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.812648</td>\n",
       "      <td>0.858088</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.901309</td>\n",
       "      <td>0.848893</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138442</td>\n",
       "      <td>0.020374</td>\n",
       "      <td>0.038130</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>153</td>\n",
       "      <td>67</td>\n",
       "      <td>245</td>\n",
       "      <td>{'learning_rate': 0.0007278521408165658, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676943</td>\n",
       "      <td>0.828722</td>\n",
       "      <td>0.872259</td>\n",
       "      <td>0.862032</td>\n",
       "      <td>0.898813</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.078758</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154218</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.055299</td>\n",
       "      <td>0.022090</td>\n",
       "      <td>1.008750</td>\n",
       "      <td>129</td>\n",
       "      <td>90</td>\n",
       "      <td>489</td>\n",
       "      <td>{'learning_rate': 1.008749959584565, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843017</td>\n",
       "      <td>0.824901</td>\n",
       "      <td>0.890374</td>\n",
       "      <td>0.871056</td>\n",
       "      <td>0.914463</td>\n",
       "      <td>0.868633</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.070125</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.030460</td>\n",
       "      <td>166</td>\n",
       "      <td>146</td>\n",
       "      <td>285</td>\n",
       "      <td>{'learning_rate': 0.0304598447170795, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.553689</td>\n",
       "      <td>0.607115</td>\n",
       "      <td>0.456417</td>\n",
       "      <td>0.646925</td>\n",
       "      <td>0.718564</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.088198</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066077</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>3.056280</td>\n",
       "      <td>160</td>\n",
       "      <td>106</td>\n",
       "      <td>113</td>\n",
       "      <td>{'learning_rate': 3.056280460373948, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.832740</td>\n",
       "      <td>0.827734</td>\n",
       "      <td>0.869519</td>\n",
       "      <td>0.880080</td>\n",
       "      <td>0.897126</td>\n",
       "      <td>0.861330</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410341</td>\n",
       "      <td>0.088831</td>\n",
       "      <td>0.034837</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>143</td>\n",
       "      <td>266</td>\n",
       "      <td>308</td>\n",
       "      <td>{'learning_rate': 0.0023759017639191486, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.577668</td>\n",
       "      <td>0.562834</td>\n",
       "      <td>0.578877</td>\n",
       "      <td>0.585267</td>\n",
       "      <td>0.608020</td>\n",
       "      <td>0.063982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084643</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.029246</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.326033</td>\n",
       "      <td>199</td>\n",
       "      <td>182</td>\n",
       "      <td>296</td>\n",
       "      <td>{'learning_rate': 3.3260326189311176, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.821476</td>\n",
       "      <td>0.867580</td>\n",
       "      <td>0.876270</td>\n",
       "      <td>0.895035</td>\n",
       "      <td>0.859237</td>\n",
       "      <td>0.026796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172679</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>152</td>\n",
       "      <td>{'learning_rate': 0.004570304197891879, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.698353</td>\n",
       "      <td>0.636298</td>\n",
       "      <td>0.709492</td>\n",
       "      <td>0.655749</td>\n",
       "      <td>0.614949</td>\n",
       "      <td>0.663032</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142236</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.041028</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>4.724942</td>\n",
       "      <td>142</td>\n",
       "      <td>475</td>\n",
       "      <td>376</td>\n",
       "      <td>{'learning_rate': 4.724941679498092, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.844137</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.900468</td>\n",
       "      <td>0.884826</td>\n",
       "      <td>0.911360</td>\n",
       "      <td>0.875153</td>\n",
       "      <td>0.030251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.037070</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>185</td>\n",
       "      <td>111</td>\n",
       "      <td>270</td>\n",
       "      <td>{'learning_rate': 0.02135085801759193, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.831950</td>\n",
       "      <td>0.813175</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.899015</td>\n",
       "      <td>0.850783</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583819</td>\n",
       "      <td>0.125459</td>\n",
       "      <td>0.043719</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>150</td>\n",
       "      <td>403</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.00027742953139919916, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.753755</td>\n",
       "      <td>0.823584</td>\n",
       "      <td>0.857821</td>\n",
       "      <td>0.862032</td>\n",
       "      <td>0.912574</td>\n",
       "      <td>0.841754</td>\n",
       "      <td>0.052461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210212</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.140125</td>\n",
       "      <td>120</td>\n",
       "      <td>103</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.14012509888078778, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.845389</td>\n",
       "      <td>0.836495</td>\n",
       "      <td>0.884759</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.903805</td>\n",
       "      <td>0.871485</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.029246</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.360350</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.36035044553422707, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.828195</td>\n",
       "      <td>0.825296</td>\n",
       "      <td>0.882687</td>\n",
       "      <td>0.875134</td>\n",
       "      <td>0.911630</td>\n",
       "      <td>0.864451</td>\n",
       "      <td>0.033219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889452</td>\n",
       "      <td>0.191556</td>\n",
       "      <td>0.046810</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>191</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.015065768432670712, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.831357</td>\n",
       "      <td>0.829578</td>\n",
       "      <td>0.895388</td>\n",
       "      <td>0.890775</td>\n",
       "      <td>0.906975</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>0.033382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210433</td>\n",
       "      <td>0.057105</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.010639606715670154, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.819170</td>\n",
       "      <td>0.822530</td>\n",
       "      <td>0.876136</td>\n",
       "      <td>0.875267</td>\n",
       "      <td>0.910146</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.034855</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>0.039728</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.061555</td>\n",
       "      <td>196</td>\n",
       "      <td>138</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.061554789842754816, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.812648</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.851203</td>\n",
       "      <td>0.901309</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799320</td>\n",
       "      <td>0.180574</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>194</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 194, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.871190</td>\n",
       "      <td>0.872193</td>\n",
       "      <td>0.911225</td>\n",
       "      <td>0.856007</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794823</td>\n",
       "      <td>0.180887</td>\n",
       "      <td>0.062585</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.018988</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01898758918336288, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.832740</td>\n",
       "      <td>0.827207</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>0.879545</td>\n",
       "      <td>0.895777</td>\n",
       "      <td>0.861009</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966205</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0013098842464545988, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.824769</td>\n",
       "      <td>0.830237</td>\n",
       "      <td>0.862299</td>\n",
       "      <td>0.861029</td>\n",
       "      <td>0.883972</td>\n",
       "      <td>0.852370</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.028170</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.562062</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.5620617355961257, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.737813</td>\n",
       "      <td>0.823715</td>\n",
       "      <td>0.860227</td>\n",
       "      <td>0.860160</td>\n",
       "      <td>0.900027</td>\n",
       "      <td>0.836192</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534208</td>\n",
       "      <td>0.111301</td>\n",
       "      <td>0.046415</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.259902</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>158</td>\n",
       "      <td>{'learning_rate': 0.25990197534503817, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.849465</td>\n",
       "      <td>0.896452</td>\n",
       "      <td>0.847609</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056694</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.033743</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0077117401004252895, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.831555</td>\n",
       "      <td>0.812582</td>\n",
       "      <td>0.863168</td>\n",
       "      <td>0.848463</td>\n",
       "      <td>0.900162</td>\n",
       "      <td>0.851066</td>\n",
       "      <td>0.029723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.015085452186796282, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.825692</td>\n",
       "      <td>0.861163</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.914193</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896339</td>\n",
       "      <td>0.176743</td>\n",
       "      <td>0.050802</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>486</td>\n",
       "      <td>{'learning_rate': 0.04001512216985859, 'max_de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.737352           0.833992           0.847259   \n",
       "1            0.822200           0.811265           0.858222   \n",
       "2            0.822266           0.812648           0.858088   \n",
       "3            0.676943           0.828722           0.872259   \n",
       "4            0.843017           0.824901           0.890374   \n",
       "5            0.553689           0.607115           0.456417   \n",
       "6            0.832740           0.827734           0.869519   \n",
       "7            0.734783           0.577668           0.562834   \n",
       "8            0.836364           0.821476           0.867580   \n",
       "9            0.698353           0.636298           0.709492   \n",
       "10           0.844137           0.835573           0.900468   \n",
       "11           0.831950           0.813175           0.863770   \n",
       "12           0.753755           0.823584           0.857821   \n",
       "13           0.845389           0.836495           0.884759   \n",
       "14           0.828195           0.825296           0.882687   \n",
       "15           0.831357           0.829578           0.895388   \n",
       "16           0.819170           0.822530           0.876136   \n",
       "17           0.822266           0.812648           0.858222   \n",
       "18           0.804348           0.821871           0.871190   \n",
       "19           0.832740           0.827207           0.870321   \n",
       "20           0.824769           0.830237           0.862299   \n",
       "21           0.737813           0.823715           0.860227   \n",
       "22           0.822266           0.812253           0.858222   \n",
       "23           0.831555           0.812582           0.863168   \n",
       "24           0.757312           0.825692           0.861163   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.847059           0.890853         0.831134        0.050790   \n",
       "1            0.851604           0.893551         0.847248        0.028981   \n",
       "2            0.850802           0.901309         0.848893        0.031141   \n",
       "3            0.862032           0.898813         0.827506        0.078758   \n",
       "4            0.871056           0.914463         0.868633        0.032076   \n",
       "5            0.646925           0.718564         0.596369        0.088198   \n",
       "6            0.880080           0.897126         0.861330        0.027003   \n",
       "7            0.578877           0.585267         0.608020        0.063982   \n",
       "8            0.876270           0.895035         0.859237        0.026796   \n",
       "9            0.655749           0.614949         0.663032        0.035991   \n",
       "10           0.884826           0.911360         0.875153        0.030251   \n",
       "11           0.846591           0.899015         0.850783        0.029236   \n",
       "12           0.862032           0.912574         0.841754        0.052461   \n",
       "13           0.887500           0.903805         0.871485        0.026014   \n",
       "14           0.875134           0.911630         0.864451        0.033219   \n",
       "15           0.890775           0.906975         0.870684        0.033382   \n",
       "16           0.875267           0.910146         0.860505        0.034855   \n",
       "17           0.851203           0.901309         0.849000        0.031154   \n",
       "18           0.872193           0.911225         0.856007        0.038397   \n",
       "19           0.879545           0.895777         0.861009        0.026762   \n",
       "20           0.861029           0.883972         0.852370        0.022012   \n",
       "21           0.860160           0.900027         0.836192        0.054912   \n",
       "22           0.849465           0.896452         0.847609        0.029619   \n",
       "23           0.848463           0.900162         0.851066        0.029723   \n",
       "24           0.857620           0.914193         0.843000        0.051485   \n",
       "\n",
       "    rank_test_score  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "0                 1       0.273891      0.051536         0.035035   \n",
       "1                 1       0.121674      0.009035         0.028192   \n",
       "2                 1       0.138442      0.020374         0.038130   \n",
       "3                 1       0.154218      0.026141         0.055299   \n",
       "4                 1       0.276985      0.070125         0.038770   \n",
       "5                 1       0.066077      0.010396         0.025852   \n",
       "6                 1       0.410341      0.088831         0.034837   \n",
       "7                 1       0.084643      0.014303         0.029246   \n",
       "8                 1       0.172679      0.036308         0.050907   \n",
       "9                 1       0.142236      0.020973         0.041028   \n",
       "10                1       0.204323      0.037070         0.031840   \n",
       "11                1       0.583819      0.125459         0.043719   \n",
       "12                1       0.210212      0.046711         0.043517   \n",
       "13                1       0.057193      0.006389         0.029246   \n",
       "14                1       0.889452      0.191556         0.046810   \n",
       "15                1       0.210433      0.057105         0.032040   \n",
       "16                1       0.215000      0.039232         0.039728   \n",
       "17                1       0.799320      0.180574         0.041191   \n",
       "18                1       0.794823      0.180887         0.062585   \n",
       "19                1       0.966205      0.176455         0.081750   \n",
       "20                1       0.056095      0.007244         0.028170   \n",
       "21                1       0.534208      0.111301         0.046415   \n",
       "22                1       0.056694      0.007632         0.033743   \n",
       "23                1       0.052402      0.007142         0.035534   \n",
       "24                1       0.896339      0.176743         0.050802   \n",
       "\n",
       "    std_score_time  param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "0         0.007026             0.857423              150                 363   \n",
       "1         0.005294             0.000114              192                  55   \n",
       "2         0.013516             0.000728              153                  67   \n",
       "3         0.022090             1.008750              129                  90   \n",
       "4         0.011122             0.030460              166                 146   \n",
       "5         0.004749             3.056280              160                 106   \n",
       "6         0.007479             0.002376              143                 266   \n",
       "7         0.000977             3.326033              199                 182   \n",
       "8         0.017002             0.004570              102                 105   \n",
       "9         0.018038             4.724942              142                 475   \n",
       "10        0.006560             0.021351              185                 111   \n",
       "11        0.011690             0.000277              150                 403   \n",
       "12        0.014111             0.140125              120                 103   \n",
       "13        0.000677             0.360350              109                   5   \n",
       "14        0.012053             0.015066              191                 500   \n",
       "15        0.007538             0.010640              104                 118   \n",
       "16        0.011896             0.061555              196                 138   \n",
       "17        0.009062             0.000100              194                 500   \n",
       "18        0.020190             0.018988              100                 500   \n",
       "19        0.021308             0.001310              200                 500   \n",
       "20        0.006746             0.562062              103                   5   \n",
       "21        0.010388             0.259902              200                 500   \n",
       "22        0.002874             0.007712              127                   5   \n",
       "23        0.004718             0.015085              200                   5   \n",
       "24        0.012049             0.040015              100                 500   \n",
       "\n",
       "    param_num_leaves                                             params  \n",
       "0                247  {'learning_rate': 0.8574231231790369, 'max_dep...  \n",
       "1                365  {'learning_rate': 0.00011414761496439964, 'max...  \n",
       "2                245  {'learning_rate': 0.0007278521408165658, 'max_...  \n",
       "3                489  {'learning_rate': 1.008749959584565, 'max_dept...  \n",
       "4                285  {'learning_rate': 0.0304598447170795, 'max_dep...  \n",
       "5                113  {'learning_rate': 3.056280460373948, 'max_dept...  \n",
       "6                308  {'learning_rate': 0.0023759017639191486, 'max_...  \n",
       "7                296  {'learning_rate': 3.3260326189311176, 'max_dep...  \n",
       "8                152  {'learning_rate': 0.004570304197891879, 'max_d...  \n",
       "9                376  {'learning_rate': 4.724941679498092, 'max_dept...  \n",
       "10               270  {'learning_rate': 0.02135085801759193, 'max_de...  \n",
       "11                50  {'learning_rate': 0.00027742953139919916, 'max...  \n",
       "12               500  {'learning_rate': 0.14012509888078778, 'max_de...  \n",
       "13               500  {'learning_rate': 0.36035044553422707, 'max_de...  \n",
       "14               500  {'learning_rate': 0.015065768432670712, 'max_d...  \n",
       "15                50  {'learning_rate': 0.010639606715670154, 'max_d...  \n",
       "16                50  {'learning_rate': 0.061554789842754816, 'max_d...  \n",
       "17                50  {'learning_rate': 0.0001, 'max_depth': 194, 'n...  \n",
       "18                50  {'learning_rate': 0.01898758918336288, 'max_de...  \n",
       "19                50  {'learning_rate': 0.0013098842464545988, 'max_...  \n",
       "20               500  {'learning_rate': 0.5620617355961257, 'max_dep...  \n",
       "21               158  {'learning_rate': 0.25990197534503817, 'max_de...  \n",
       "22               500  {'learning_rate': 0.0077117401004252895, 'max_...  \n",
       "23                50  {'learning_rate': 0.015085452186796282, 'max_d...  \n",
       "24               486  {'learning_rate': 0.04001512216985859, 'max_de...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(est.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T00:43:50.467903Z",
     "start_time": "2019-03-08T00:43:49.436824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liam\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.06427451, 0.90985372, 0.30625736, 0.85428916, 0.11371714,\n",
       "       0.06081841, 0.11671647, 0.3914611 , 0.32082449, 0.91344565,\n",
       "       0.81357712, 0.83355016, 0.07548558, 0.0785559 , 0.69627998,\n",
       "       0.79279278, 0.31660328, 0.0571257 , 0.53793957, 0.69908025,\n",
       "       0.07179157, 0.07816423, 0.48915564, 0.17888923, 0.10037492,\n",
       "       0.1614398 , 0.05980076, 0.17204782, 0.69908025, 0.04793298,\n",
       "       0.24800219, 0.92060041, 0.69908025, 0.09879008, 0.23334793,\n",
       "       0.14906571, 0.05980076, 0.07548558, 0.60035827, 0.50607611,\n",
       "       0.31721814, 0.79822668, 0.06402198, 0.91317755, 0.53679976,\n",
       "       0.07623034, 0.0552934 , 0.69908025, 0.06711605, 0.60035827,\n",
       "       0.31660328, 0.08398018, 0.91172312, 0.79668138, 0.13581097,\n",
       "       0.08396178, 0.80956815, 0.12650701, 0.86783623, 0.31660328,\n",
       "       0.09866948, 0.90985372, 0.19113065, 0.31660328, 0.12596769,\n",
       "       0.11966863, 0.80808882, 0.06588729, 0.40252421, 0.04750199,\n",
       "       0.08960677, 0.0965991 , 0.11170035, 0.07385849, 0.1373142 ,\n",
       "       0.0675684 , 0.04793298, 0.07623034, 0.62761122, 0.37364059,\n",
       "       0.04482761, 0.08516684, 0.69908025, 0.17694292, 0.80956815,\n",
       "       0.34642121, 0.06156948, 0.07623034, 0.63602884, 0.06192134,\n",
       "       0.12347825, 0.08398018, 0.20737904, 0.07783747, 0.06575419,\n",
       "       0.07623034, 0.10001762, 0.21373205, 0.79028858, 0.06735839,\n",
       "       0.5138351 , 0.04793298, 0.21373205, 0.08413592, 0.10699344,\n",
       "       0.11436311, 0.5138351 , 0.04819893, 0.07088711, 0.31608855,\n",
       "       0.14906571, 0.55685459, 0.07041846, 0.32082449, 0.55685459,\n",
       "       0.08054752, 0.0806641 , 0.07398972, 0.19710969, 0.10037492,\n",
       "       0.11170035, 0.07623034, 0.12974019, 0.80201532, 0.15744042,\n",
       "       0.32371865, 0.05586913, 0.05818951, 0.31608855, 0.06782484,\n",
       "       0.08727587, 0.0645904 , 0.36297263, 0.79668138, 0.04926675,\n",
       "       0.06593666, 0.79271875, 0.22669367, 0.04157483, 0.20590171,\n",
       "       0.56324371, 0.5138351 , 0.42966124, 0.05804331, 0.04157483,\n",
       "       0.06156948, 0.12239871, 0.18470987, 0.10309237, 0.08007888,\n",
       "       0.08505932, 0.85975382, 0.12683432, 0.114547  , 0.03601629,\n",
       "       0.1940184 , 0.69627998, 0.12963241, 0.05887579, 0.09780345,\n",
       "       0.11191947, 0.79890487, 0.08757386, 0.04157483, 0.31660328,\n",
       "       0.39466394, 0.87245011, 0.1614398 , 0.05686088, 0.12495026,\n",
       "       0.10001762, 0.31660328, 0.72659525, 0.08054752, 0.11671647,\n",
       "       0.11623087, 0.08074913, 0.91172312, 0.08960677, 0.06782484,\n",
       "       0.10037492, 0.08303295, 0.31660328, 0.62761122, 0.28871005,\n",
       "       0.08396178, 0.56769138, 0.22740593, 0.1077802 , 0.07088711,\n",
       "       0.80201532, 0.04186895, 0.53679976, 0.70061618, 0.91172312,\n",
       "       0.90908179, 0.05586913, 0.12642332, 0.69908025, 0.80956815,\n",
       "       0.08113446, 0.09780345, 0.06782484, 0.0768503 , 0.06588729,\n",
       "       0.72659525, 0.08417324, 0.0674741 , 0.69627998, 0.17337413,\n",
       "       0.05818951, 0.79307798, 0.06427451, 0.08960677, 0.05640396,\n",
       "       0.90716215, 0.30625736, 0.1121865 , 0.90985372, 0.08960677,\n",
       "       0.06588729, 0.08113446, 0.12683432, 0.04793298, 0.20933163,\n",
       "       0.04482761, 0.04186895, 0.0645904 , 0.04157483, 0.10037492,\n",
       "       0.85428916, 0.13698759, 0.08505932, 0.10037492, 0.04227803,\n",
       "       0.69908025, 0.07337614, 0.86783623, 0.04186895, 0.07816423,\n",
       "       0.56324371, 0.56769138, 0.08516684, 0.06427451, 0.13278926,\n",
       "       0.19113065, 0.5138351 , 0.80694693, 0.21725672, 0.07337614,\n",
       "       0.03601629, 0.32082449, 0.14875183, 0.07789657, 0.48831093,\n",
       "       0.36681969, 0.92293548, 0.85428916, 0.90716215, 0.78986391,\n",
       "       0.05586913, 0.31660328, 0.17858099, 0.10516489, 0.69908025,\n",
       "       0.07816423, 0.05261184, 0.0780074 , 0.85066114, 0.85021167,\n",
       "       0.08396178, 0.06969192, 0.78986391, 0.23795115, 0.69908025,\n",
       "       0.85472848, 0.5138351 , 0.03718775, 0.31660328, 0.53793957,\n",
       "       0.0806641 , 0.12239871, 0.04157483, 0.06588729, 0.55936568,\n",
       "       0.2012955 , 0.08960677, 0.22335389, 0.08007888, 0.5138351 ,\n",
       "       0.85428916, 0.91344565, 0.1709619 , 0.5941195 , 0.32550883,\n",
       "       0.65520335, 0.28440111, 0.93719791, 0.12596769, 0.90908179,\n",
       "       0.69908025, 0.05257925, 0.37533254, 0.86706217, 0.3183635 ,\n",
       "       0.64083333, 0.92293548, 0.91344565, 0.31465491, 0.94203784,\n",
       "       0.94167199, 0.9430372 , 0.87506007, 0.26536834, 0.12304487,\n",
       "       0.55879196, 0.87506007, 0.13263311, 0.9430372 , 0.9430372 ,\n",
       "       0.26006797, 0.33821042, 0.86465841, 0.87506007, 0.13803217,\n",
       "       0.9430372 , 0.06533931, 0.84713178, 0.29183499, 0.94167199,\n",
       "       0.3151302 , 0.70381958, 0.55476694, 0.38903762, 0.94322868,\n",
       "       0.2000895 , 0.68835007, 0.9430372 , 0.08896935, 0.6937623 ,\n",
       "       0.74443545, 0.9430372 , 0.32050922, 0.32936118, 0.17976378,\n",
       "       0.85996911, 0.84350901, 0.37792331, 0.74443545, 0.09115012,\n",
       "       0.2947632 , 0.65206431, 0.48109679, 0.33440115, 0.27271321,\n",
       "       0.40708774, 0.94167199, 0.84713178, 0.70184823, 0.70184823,\n",
       "       0.19304722, 0.34482136, 0.37499179, 0.07781798, 0.52785023,\n",
       "       0.3255762 , 0.92847221, 0.6376305 , 0.70571042, 0.94167199,\n",
       "       0.69043965, 0.37502484, 0.50161044, 0.66071265, 0.56300587,\n",
       "       0.94099008, 0.60858134, 0.57033861, 0.40668133, 0.35399178,\n",
       "       0.9430372 , 0.70375987, 0.41037411, 0.94063051, 0.2000895 ,\n",
       "       0.3549405 , 0.26411546, 0.84713178, 0.25250887, 0.85996911,\n",
       "       0.51797152, 0.24551659, 0.3833414 , 0.94167199, 0.45341019,\n",
       "       0.24551659, 0.50768696, 0.15761142, 0.27159183, 0.86387473,\n",
       "       0.09077638, 0.46599393, 0.4606194 , 0.31615542, 0.55376979,\n",
       "       0.24938528, 0.08104398, 0.74443545, 0.24273428, 0.15393993,\n",
       "       0.2000895 , 0.24903197, 0.94275886, 0.22847654, 0.08896935,\n",
       "       0.45792128, 0.94063051, 0.85996911, 0.32896922, 0.22678183,\n",
       "       0.23430571, 0.24564633, 0.26536834, 0.38864679, 0.34049929,\n",
       "       0.23278507, 0.87216862, 0.87506007, 0.25250887, 0.41037411,\n",
       "       0.7205734 , 0.37792331, 0.85283236, 0.37533254, 0.68908697,\n",
       "       0.94167199, 0.2388308 , 0.85976022, 0.44401675, 0.38151136,\n",
       "       0.82465171, 0.43424416, 0.39038483, 0.86387473, 0.31612391,\n",
       "       0.78692849, 0.86295815, 0.75392188, 0.66611606, 0.60629099,\n",
       "       0.21171556, 0.52785023, 0.70159753, 0.61184376, 0.3183635 ,\n",
       "       0.27806308, 0.59630617, 0.9403628 , 0.8098685 , 0.25250887,\n",
       "       0.7056272 , 0.19601269, 0.68743037, 0.17161908, 0.3183635 ,\n",
       "       0.07781798, 0.22847654, 0.60345639, 0.25250887, 0.68565951,\n",
       "       0.23278507, 0.09077638, 0.8561113 , 0.85996911, 0.55680795,\n",
       "       0.64657653, 0.24938528, 0.35010539, 0.26006797, 0.65944392,\n",
       "       0.19038848, 0.22847654, 0.08896935, 0.35605347, 0.61102713,\n",
       "       0.15393993, 0.94275886, 0.60466784, 0.43826732, 0.71678259,\n",
       "       0.52785023, 0.26006797, 0.60629099, 0.58102584, 0.35447465,\n",
       "       0.54107602, 0.92847221, 0.52544607, 0.9430372 , 0.38762565,\n",
       "       0.44681566, 0.71104461, 0.70571042, 0.36860305, 0.94167199,\n",
       "       0.61392441, 0.86040521, 0.66941613, 0.35315575, 0.47511162,\n",
       "       0.32805946, 0.3183635 , 0.75392188, 0.92847221, 0.40606655,\n",
       "       0.68743037, 0.84713178, 0.50920958, 0.85627606, 0.28690266,\n",
       "       0.94203784, 0.22335389, 0.27271321, 0.93024732, 0.27639905,\n",
       "       0.08585514, 0.8098685 , 0.63001122, 0.09077638, 0.20365945,\n",
       "       0.88375877, 0.27639905, 0.40825969, 0.54673887, 0.52044271,\n",
       "       0.87183246, 0.71174508, 0.94203784, 0.52544607, 0.94178404,\n",
       "       0.94275886, 0.20772142, 0.20772142, 0.29429572, 0.61184376,\n",
       "       0.30282656, 0.87506007, 0.51220537, 0.21913421, 0.68575648,\n",
       "       0.56869744, 0.28666569, 0.21298293, 0.28163088, 0.60415945,\n",
       "       0.59630617, 0.92768944, 0.62741812, 0.94124514, 0.2119778 ,\n",
       "       0.25250887, 0.07955237, 0.34247803, 0.3183635 , 0.45792128,\n",
       "       0.28641975, 0.33457992, 0.38545423, 0.27639905, 0.28690266,\n",
       "       0.07954733, 0.92773953, 0.75392188, 0.70571042, 0.57759272,\n",
       "       0.34003664, 0.84713178, 0.94124514, 0.54052503, 0.27743537,\n",
       "       0.77624384, 0.91789978, 0.13102058, 0.71620779, 0.3167425 ,\n",
       "       0.91383005, 0.16994283, 0.11200951, 0.35447465, 0.3183635 ,\n",
       "       0.07781798, 0.91306575, 0.0794865 , 0.70571042, 0.12888691,\n",
       "       0.11108935, 0.94053959, 0.07814296, 0.27271321, 0.25497142,\n",
       "       0.77624384, 0.2000895 , 0.64657653, 0.22090665, 0.48768327,\n",
       "       0.09407544, 0.21434669, 0.54724185, 0.82104347, 0.91364893,\n",
       "       0.26617098, 0.04839977, 0.64217198, 0.069988  , 0.23797879,\n",
       "       0.79382477, 0.10930763, 0.48673199, 0.88554163, 0.13159724,\n",
       "       0.21602596, 0.25997252, 0.17812014, 0.12535609, 0.11786311,\n",
       "       0.10113267, 0.18413735, 0.88494806, 0.16211738, 0.0502084 ,\n",
       "       0.10799391, 0.06413457, 0.42796985, 0.11029092, 0.21989265,\n",
       "       0.88790698, 0.27743537, 0.14121262, 0.25507075, 0.11073306,\n",
       "       0.13313532, 0.85891066, 0.286774  , 0.18392381, 0.62726148,\n",
       "       0.25497142, 0.14117448, 0.10113267, 0.0502084 , 0.40652293,\n",
       "       0.0795319 , 0.90703061, 0.12901821, 0.51113291, 0.53316883,\n",
       "       0.19644962, 0.0795319 , 0.56570651, 0.10804211, 0.10609704,\n",
       "       0.13081693, 0.15629011, 0.18648759, 0.08361825, 0.13390477,\n",
       "       0.20981231, 0.12930251, 0.08639451, 0.22090665, 0.9387352 ,\n",
       "       0.91249409, 0.40897499, 0.18413735, 0.18011573, 0.04839977,\n",
       "       0.14679771, 0.12631704, 0.31417801, 0.25507075, 0.44250189,\n",
       "       0.39197034, 0.46493335, 0.11703908, 0.34308657, 0.09688652,\n",
       "       0.27265951, 0.34308657, 0.126493  , 0.14679771, 0.90853805,\n",
       "       0.47472016, 0.42639293, 0.18392381, 0.25460845, 0.12938385,\n",
       "       0.12189299, 0.22090665, 0.51113291, 0.25589966, 0.08616759,\n",
       "       0.86560188, 0.60111747, 0.32524814, 0.16193564, 0.16936331,\n",
       "       0.11887071, 0.85384285, 0.41124042, 0.87811888, 0.1748342 ,\n",
       "       0.84787339, 0.38374043, 0.21788336, 0.20923779, 0.20294549,\n",
       "       0.08952048, 0.91117685, 0.83779022, 0.08887573, 0.17501677,\n",
       "       0.92267668, 0.20287528, 0.21736129, 0.20294549, 0.50341598,\n",
       "       0.11703908, 0.88932068, 0.51113291, 0.18533604, 0.40652293,\n",
       "       0.91386081, 0.65623249, 0.04839977, 0.10804211, 0.10804211,\n",
       "       0.14668515, 0.25507075, 0.44250189, 0.0795319 , 0.0795319 ,\n",
       "       0.32597595, 0.47472016, 0.82367408, 0.11601595, 0.21993034,\n",
       "       0.11152938, 0.24324765, 0.88790698, 0.46006488, 0.2287902 ,\n",
       "       0.88554163, 0.66567789, 0.21835102, 0.12564819, 0.91268109,\n",
       "       0.6858835 , 0.18874597, 0.12849775, 0.23797879, 0.94237129,\n",
       "       0.08948605, 0.08470876, 0.15617595, 0.94231313, 0.2996825 ,\n",
       "       0.91268109, 0.17625687, 0.54011052, 0.13814014, 0.27743537,\n",
       "       0.11374242, 0.12110953, 0.86168573, 0.10080521, 0.87425897,\n",
       "       0.14988037, 0.069988  , 0.41378795, 0.0502084 , 0.90899409,\n",
       "       0.49459887, 0.87303099, 0.54221459, 0.11938302, 0.16193564,\n",
       "       0.16193564, 0.39816961, 0.34308657, 0.7081179 , 0.23888783,\n",
       "       0.069988  , 0.30850842, 0.286774  , 0.24429333, 0.16211738,\n",
       "       0.20137734, 0.87425897, 0.21407659, 0.24809063, 0.26907934,\n",
       "       0.21736129, 0.91778121, 0.6821188 , 0.66567789, 0.15357853,\n",
       "       0.23310964, 0.2101053 , 0.39816961, 0.20137734, 0.94229397,\n",
       "       0.16211738, 0.12146537, 0.22082246, 0.286774  , 0.21993034,\n",
       "       0.11029092, 0.40652293, 0.23593867, 0.08470876, 0.34308657,\n",
       "       0.91306927, 0.1489331 , 0.20213095, 0.30990891, 0.34308657,\n",
       "       0.04839977, 0.18392381, 0.68721748, 0.069988  , 0.91426219,\n",
       "       0.32524814, 0.7081179 , 0.10435739, 0.12631721, 0.13941491,\n",
       "       0.91789978, 0.1154482 , 0.11187194, 0.38695125, 0.24429333,\n",
       "       0.13499724, 0.26961708, 0.90789319, 0.14946131, 0.26646507,\n",
       "       0.08616759, 0.10474576, 0.19581169, 0.33241021, 0.94262178,\n",
       "       0.34308657, 0.10485301, 0.41090833, 0.90703061, 0.87425897,\n",
       "       0.24593598, 0.90732569, 0.29893547, 0.49966503, 0.10435739,\n",
       "       0.09878883, 0.12506733, 0.87425897, 0.286774  , 0.10834069,\n",
       "       0.85384285, 0.75846545, 0.41963311, 0.13841773, 0.67685911,\n",
       "       0.16211738, 0.91453285, 0.20213095, 0.18742583, 0.89744596,\n",
       "       0.49459887, 0.11853754, 0.14117448, 0.0795319 , 0.91502081,\n",
       "       0.84253405, 0.17018192, 0.32779885, 0.12830127, 0.16193564,\n",
       "       0.54091795, 0.12830587, 0.90703061, 0.33651806, 0.45682595,\n",
       "       0.2287902 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_predict(est.best_estimator_, X, y, method=\"predict_proba\")[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
